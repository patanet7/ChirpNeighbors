# Bird Image/GIF Generation Model Configuration

# Base Model Configuration
base_model:
  name: "stabilityai/sdxl-turbo"
  revision: "main"
  variant: "fp16"  # Use FP16 for faster inference
  cache_dir: "./models/base"

  # Model components
  vae:
    name: "madebyollin/sdxl-vae-fp16-fix"  # Fixed VAE for FP16
  scheduler:
    type: "EulerAncestralDiscreteScheduler"
    num_inference_steps: 4  # SDXL Turbo optimized for 4 steps

# LoRA Configuration
lora:
  enabled: true
  rank: 64  # LoRA rank (higher = more capacity, slower)
  alpha: 64
  dropout: 0.1
  target_modules:
    - "to_q"
    - "to_k"
    - "to_v"
    - "to_out.0"
    - "proj_in"
    - "proj_out"

  # Bird family LoRAs (priority order)
  families:
    - name: "passeriformes"
      description: "Songbirds (50% of species)"
      priority: 1
      training_images: 2000
    - name: "charadriiformes"
      description: "Shorebirds"
      priority: 2
      training_images: 1500
    - name: "accipitriformes"
      description: "Raptors"
      priority: 3
      training_images: 1000
    - name: "anseriformes"
      description: "Waterfowl"
      priority: 4
      training_images: 1500
    - name: "piciformes"
      description: "Woodpeckers"
      priority: 5
      training_images: 800

# ControlNet Configuration
controlnet:
  enabled: true
  models:
    - type: "openpose"
      name: "lllyasviel/control_v11p_sd15_openpose"
      conditioning_scale: 0.8
    - type: "depth"
      name: "lllyasviel/control_v11f1p_sd15_depth"
      conditioning_scale: 0.6

# Image Generation Settings
generation:
  default_resolution: [1024, 1024]
  supported_resolutions:
    thumbnail: [256, 256]
    small: [512, 512]
    medium: [1024, 1024]
    large: [2048, 2048]

  # Quality settings
  guidance_scale: 1.0  # SDXL Turbo works best with 1.0
  num_inference_steps: 4
  negative_prompt: "cartoon, drawing, anime, blurry, low quality, watermark, text, signature, out of focus, mutation, deformed, ugly"

  # Batch settings
  batch_size: 4
  max_concurrent_generations: 8

# GIF/Video Generation Settings
animation:
  enabled: true

  # AnimateDiff settings
  motion_module:
    name: "guoyww/animatediff-motion-adapter-v1-5-2"
    num_frames: 16
    fps: 8
    duration_seconds: 2

  # Stable Video Diffusion (alternative)
  svd:
    name: "stabilityai/stable-video-diffusion-img2vid-xt"
    num_frames: 25
    fps: 8
    motion_bucket_id: 127
    noise_aug_strength: 0.02

  # Output settings
  format: "webp"  # webp, gif, or mp4
  quality: 90
  optimize: true
  loop: true

# Prompt Engineering
prompts:
  template: |
    A {quality} photograph of {species_common_name} ({species_scientific_name}), {pose}, {plumage_description}, {key_features}, {habitat_context}, {lighting}, {photography_style}

  quality_adjectives:
    - "professional wildlife"
    - "award-winning"
    - "high-resolution"
    - "sharp"

  photography_styles:
    - "professional wildlife photography"
    - "National Geographic style"
    - "nature documentary quality"
    - "Audubon field guide style"

  lighting_options:
    - "natural lighting"
    - "golden hour"
    - "soft diffused light"
    - "dramatic lighting"

  pose_library:
    - "perched on a branch"
    - "in flight with wings spread"
    - "foraging on the ground"
    - "singing with beak open"
    - "preening feathers"
    - "feeding on berries"
    - "in water swimming"
    - "diving for fish"

# Training Configuration
training:
  # General settings
  output_dir: "./models/lora"
  logging_dir: "./logs"
  seed: 42

  # Optimization
  optimizer: "adamw"
  learning_rate: 1e-4
  lr_scheduler: "cosine"
  lr_warmup_steps: 500
  weight_decay: 0.01
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1e-8
  max_grad_norm: 1.0

  # Training parameters
  num_train_epochs: 100
  train_batch_size: 4
  gradient_accumulation_steps: 4
  mixed_precision: "fp16"

  # Checkpointing
  save_steps: 500
  save_total_limit: 5
  checkpointing_steps: 500
  resume_from_checkpoint: "latest"

  # Validation
  validation_epochs: 10
  validation_prompts:
    - "A bird perched on a branch, natural setting"
    - "Bird in flight, blue sky background"
    - "Close-up of bird head, detailed feathers"

  # Data augmentation
  augmentation:
    enabled: true
    random_flip: true
    random_crop: false
    color_jitter:
      brightness: 0.1
      contrast: 0.1
      saturation: 0.1
      hue: 0.05
    random_rotation: 5  # degrees

# Dataset Configuration
dataset:
  # Data sources
  sources:
    - name: "inaturalist"
      api_url: "https://api.inaturalist.org/v1/observations"
      license_filter: ["cc0", "cc-by", "cc-by-sa"]
    - name: "macaulay_library"
      api_url: "https://search.macaulaylibrary.org/api/v1"
    - name: "flickr"
      api_url: "https://api.flickr.com/services/rest/"
      license_filter: ["cc-by-2.0", "cc-by-sa-2.0", "cc0"]

  # Image filtering
  min_resolution: [512, 512]
  max_aspect_ratio: 2.0
  quality_threshold: 0.7  # BRISQUE score

  # Storage
  local_path: "./training/data"
  s3_bucket: "chirpneighbors-training-data"
  cache_size_gb: 100

# Inference Configuration
inference:
  # Server settings
  host: "0.0.0.0"
  port: 8001
  workers: 4

  # GPU settings
  device: "cuda"
  gpu_memory_fraction: 0.9
  enable_tf32: true
  enable_cudnn_benchmark: true

  # Optimization
  compile: true  # torch.compile()
  use_xformers: true
  use_tensorrt: false  # Enable for production
  quantization: "fp16"  # Options: fp16, int8, none

  # Caching
  cache_backend: "redis"
  cache_ttl: 2592000  # 30 days
  cache_max_size_gb: 50
  preload_models: true

  # Rate limiting
  max_requests_per_minute: 60
  max_concurrent_jobs: 10
  queue_size: 100

  # Output
  output_format: "webp"
  output_quality: 95
  cdn_upload: true
  cdn_endpoint: "https://cdn.chirpneighbors.com"

# Monitoring & Logging
monitoring:
  # Experiment tracking
  wandb:
    enabled: true
    project: "chirpneighbors-bird-generation"
    entity: "chirpneighbors"

  mlflow:
    enabled: true
    tracking_uri: "http://localhost:5000"
    experiment_name: "bird-image-generation"

  # Prometheus metrics
  prometheus:
    enabled: true
    port: 9090
    metrics:
      - generation_duration_seconds
      - cache_hit_rate
      - gpu_utilization_percent
      - queue_length
      - error_rate

  # Logging
  log_level: "INFO"
  log_format: "json"
  log_file: "./logs/model.log"

# Quality Assurance
quality:
  # Automated checks
  species_verification:
    enabled: true
    model: "google/vit-base-patch16-224"  # Classification model
    confidence_threshold: 0.9

  image_quality:
    enabled: true
    brisque_threshold: 35  # Lower is better
    min_sharpness: 0.3

  # Human review
  review_sample_rate: 0.1  # 10% of generations
  expert_review: true
  community_feedback: true

# Resource Limits
resources:
  # GPU
  max_gpu_memory_gb: 24
  max_gpu_utilization_percent: 90

  # Storage
  max_model_cache_gb: 100
  max_output_cache_gb: 500
  max_training_data_gb: 1000

  # Compute
  max_cpu_percent: 80
  max_ram_gb: 64

# Ethical AI
ethics:
  # Bias monitoring
  species_equity: true
  geographic_diversity: true

  # Transparency
  watermark: false  # No watermarks per design
  metadata:
    include_generation_info: true
    include_model_version: true
    include_prompt: false  # Privacy

  # Attribution
  credit_training_data: true
  respect_licenses: true

  # Environmental
  carbon_tracking: true
  optimize_energy: true
